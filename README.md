# ğŸ¬ HumanFeedback
ğŸ‘¨ Helping Humans Teach AIs ğŸ¤– 

# What is this?
There is an emerging set of applications built centered around AI API calls (like GPT3). Data from the user-AI interaction can be evaluated, (re)labeled and then used to improve the model (through finetuning or RLHF). But just storing the results in a unstructured manner doesn't make the data very useful. There is a need for a simple and standardized pipeline to go through these steps. 

This library aims to help AI apps to easily incorporate Human Feedback and improve their models.

This library is inspired on LangChain work and is aimed to work together with it.

# What can this help with?
### ğŸ’¾ Store all the inputs/outputs that goes through langchain in a persistent DB

*Colab Example:** https://colab.research.google.com/drive/1Oyc5fCtq07CfwHfi9ghI52Pf-eqzB0LK?usp=sharing

### ğŸ”ï¸ Rank the most relevant examples to be evaluated by a human (coming soon)

(coming soon)

### ğŸ“œ Export relevant examples to be (re)labeled (coming soon)

(coming soon)

### ğŸ§‘â€ğŸ“ Elements for an interface to provide feedback more easily (coming soon)

(coming soon)

### ğŸ’ Finetune GPT3 with the annotated data (coming soon)

(coming soon)